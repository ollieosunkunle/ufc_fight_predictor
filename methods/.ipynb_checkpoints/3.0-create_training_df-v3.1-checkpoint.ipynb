{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import various useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con = \"sqlite:///../database/ufc_data.db\"\n",
    "con = create_engine(sql_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_df = pd.read_sql(\"SELECT * FROM clean_fighter_data\", con)\n",
    "bout_df = pd.read_sql(\"SELECT * FROM clean_bout_data\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add losses to the data for fighter_1\n",
    "all_data = bout_df.copy()\n",
    "all_data_losses = all_data[all_data.results=='win'].copy() #Make a copy of all_data with just the wins\n",
    "\n",
    "all_data_losses['results'] = all_data_losses.results.str.replace(\"win\",\"loss\") #Replace win with loss\n",
    "all_data_losses = all_data_losses.rename(columns={'fighter_1':'temp'}).rename(columns={'fighter_2':'fighter_1'}).rename(columns={'temp':'fighter_2'}) #Rename the columns\n",
    "all_data_doubled = pd.concat([all_data,all_data_losses]).sort_values(by='date') #Aggregate data and sort the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ollieosunkunle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Count the number of ufc wins\n",
    "\n",
    "all_data_doubled['ufc_f1_wins_and_losses'] = all_data_doubled.groupby(by=['fighter_1','results']).event_name.cumcount() + 1 #Long forms wins and losses\n",
    "all_data_mini = all_data_doubled[['date','fighter_1','fighter_2','results','ufc_f1_wins_and_losses']].copy() #Subset the data in preparation for pivotting\n",
    "\n",
    "all_data_pivot = all_data_mini.pivot_table(index=['date','fighter_1','fighter_2'], columns='results').reset_index() #Pivot to create wide columns of wins\n",
    "all_data_pivot.columns = ['date','fighter_1','fighter_2','draw','loss','nc','win'] #Rename the columns to remove multi-indexing\n",
    "\n",
    "#filled_nas = all_data_pivot.groupby(by='fighter_1')['draw','loss','nc','win'].fillna(method='bfill') #Fillnas - first fill with previous values\n",
    "filled_nas = all_data_pivot.groupby(by='fighter_1')['draw','loss','nc','win'].fillna(method='ffill') #Fillnas - then fill with forward values\n",
    "\n",
    "for i in ['draw','loss','nc','win']: #Replace the columns in all_data pivot with that from filled_nas\n",
    "    all_data_pivot[i] = filled_nas[i]\n",
    "    all_data_pivot[i] = all_data_pivot.groupby(by='fighter_1')[i].shift()\n",
    "    \n",
    "all_data_pivot = all_data_pivot.fillna(0) #Fill the remaining NAs wtith zeros\n",
    "all_data_doubled = all_data_doubled.merge(all_data_pivot, on=['date','fighter_1','fighter_2']) #Left merge all_data_doubled - creates draw, loss, nc and win columns\n",
    "all_data_doubled = all_data_doubled.drop(columns=['ufc_f1_wins_and_losses']) #Drop the unneeded column\n",
    "\n",
    "for i in ['draw','loss','nc','win']:\n",
    "    all_data_doubled = all_data_doubled.rename(columns={i:'ufc_'+i}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge in the fighter df\n",
    "\n",
    "fighter_df = fighter_df.rename(columns={'wins':'max_wins','losses':'max_losses','draws':'max_draws'})\n",
    "\n",
    "fighter_columns = ['height', 'weight', 'reach', 'stance', 'dob',\n",
    "       'strikes_landed_per_min', 'strike_accuracy', 'strikes_absorbed_per_min',\n",
    "       'strike_defense', 'takedowns_per_15_min', 'takedown_accuracy',\n",
    "       'takedown_defense', 'submission_attempts_per_15_min', 'max_wins',\n",
    "       'max_losses', 'max_draws', 'total_fights', 'win_pct', 'loss_pct',\n",
    "       'draw_pct']\n",
    "\n",
    "all_data_doubled = all_data_doubled.merge(fighter_df,left_on='fighter_1',right_on='fighter_name')\n",
    "\n",
    "for i in fighter_columns:\n",
    "    all_data_doubled = all_data_doubled.rename(columns={i:'f1_'+i}) \n",
    "    \n",
    "all_data_doubled = all_data_doubled.drop(columns='fighter_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create total fights features\n",
    "\n",
    "max_fights = all_data_doubled[['fighter_1','ufc_win','ufc_draw','ufc_loss','ufc_nc']].groupby(by='fighter_1').max()\n",
    "max_fights.columns = ['f1_max_ufc_win', 'f1_max_ufc_draw', 'f1_max_ufc_loss', 'f1_max_ufc_nc']\n",
    "all_data_doubled = all_data_doubled.merge(max_fights,on='fighter_1',how='left')\n",
    "\n",
    "all_data_doubled = all_data_doubled.rename(columns={'ufc_win':'f1_ufc_win','ufc_draw':'f1_ufc_draw','ufc_loss':'f1_ufc_loss','ufc_nc':'f1_ufc_nc'}) #Renaming of columns to make fighter explicit\n",
    "\n",
    "ufc_cols = ['f1_ufc_win','f1_ufc_loss','f1_ufc_draw']\n",
    "max_ufc_cols = ['f1_max_ufc_win', 'f1_max_ufc_loss', 'f1_max_ufc_draw']\n",
    "max_all_cols = ['f1_max_wins', 'f1_max_losses', 'f1_max_draws']\n",
    "all_cols = ['f1_all_win','f1_all_loss','f1_all_draw']\n",
    "\n",
    "for i in range(len(ufc_cols)):\n",
    "    all_data_doubled[all_cols[i]] = all_data_doubled[max_all_cols[i]] - all_data_doubled[max_ufc_cols[i]] + all_data_doubled[ufc_cols[i]]\n",
    "    \n",
    "all_data_doubled = all_data_doubled.drop(columns=['f1_max_wins','f1_max_losses','f1_max_draws','f1_max_ufc_win','f1_max_ufc_draw','f1_max_ufc_loss','f1_max_ufc_nc'])\n",
    "all_data_doubled['f1_total_fights'] = all_data_doubled['f1_all_win'] + all_data_doubled['f1_all_loss'] + all_data_doubled['f1_all_draw'] + all_data_doubled['f1_ufc_nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the leakage columns\n",
    "leakage_cols = ['f1_strikes_landed_per_min','f1_strike_accuracy','f1_strikes_absorbed_per_min','f1_strike_defense','f1_takedowns_per_15_min','f1_takedown_accuracy','f1_takedown_defense','f1_submission_attempts_per_15_min','f1_win_pct','f1_loss_pct','f1_draw_pct']\n",
    "all_data_doubled = all_data_doubled.drop(columns = leakage_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create total UFC fights feature\n",
    "all_data_doubled['f1_ufc_total_fights'] = all_data_doubled['f1_ufc_draw'] + all_data_doubled['f1_ufc_loss'] + all_data_doubled['f1_ufc_nc'] + all_data_doubled['f1_ufc_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum cumulative features\n",
    "orig_f1_features = ['no_rounds','total_fight_time','fighter_1_strikes','fighter_1_td','fighter_1_sub']\n",
    "cum_f1_target = ['f1_cum_rnd','f1_cum_ftime','f1_cum_strikes','f1_cum_td','f1_cum_sub']\n",
    "\n",
    "for i in range(len(orig_f1_features)):\n",
    "    all_data_doubled[cum_f1_target[i]] = all_data_doubled.groupby(by=['fighter_1'])[orig_f1_features[i]].cumsum()\n",
    "    \n",
    "orig_f2_features = ['no_rounds','total_fight_time','fighter_2_strikes','fighter_2_td','fighter_2_sub']\n",
    "cum_f2_target = ['f2_cum_rnd','f2_cum_ftime','f2_cum_strikes','f2_cum_td','f2_cum_sub']\n",
    "\n",
    "for i in range(len(orig_f2_features)):\n",
    "    all_data_doubled[cum_f2_target[i]] = all_data_doubled.groupby(by=['fighter_2'])[orig_f2_features[i]].cumsum()\n",
    "    \n",
    "f1_per_min_orig = ['f1_cum_strikes','f1_cum_td','f1_cum_sub']\n",
    "f1_per_min_target = ['f1_stpm','f1_tdpm','f1_subpm']\n",
    "\n",
    "for i in range(len(f1_per_min_orig)):\n",
    "    all_data_doubled[f1_per_min_target[i]] = all_data_doubled[f1_per_min_orig[i]] / all_data_doubled['f1_cum_ftime']\n",
    "    \n",
    "f2_per_min_orig = ['f2_cum_strikes','f2_cum_td','f2_cum_sub']\n",
    "f2_per_min_target = ['f2_stpm','f2_tdpm','f2_subpm']\n",
    "\n",
    "for i in range(len(f2_per_min_orig)):\n",
    "    all_data_doubled[f2_per_min_target[i]] = all_data_doubled[f2_per_min_orig[i]] / all_data_doubled['f2_cum_ftime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a win streak feature for f1\n",
    "all_data_doubled['results_2'] = np.where(all_data_doubled.results=='win',0,1)\n",
    "all_data_doubled['cumsum'] = all_data_doubled.groupby(by=['fighter_1']).results_2.cumsum()\n",
    "all_data_doubled['val'] = np.where(all_data_doubled.results=='win',1,0)\n",
    "all_data_doubled['f1_win_streak'] = all_data_doubled.groupby(by=['fighter_1','cumsum']).val.cumsum()\n",
    "all_data_doubled['f1_win_streak'] = all_data_doubled.groupby(by=['fighter_1'])['f1_win_streak'].shift(periods=1,fill_value=0)\n",
    "all_data_doubled = all_data_doubled.drop(columns=['results_2','cumsum','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a loss streak feature for f1\n",
    "all_data_doubled['results_2'] = np.where(all_data_doubled.results=='loss',0,1)\n",
    "all_data_doubled['cumsum'] = all_data_doubled.groupby(by=['fighter_1']).results_2.cumsum()\n",
    "all_data_doubled['val'] = np.where(all_data_doubled.results=='loss',1,0)\n",
    "all_data_doubled['f1_loss_streak'] = all_data_doubled.groupby(by=['fighter_1','cumsum']).val.cumsum()\n",
    "all_data_doubled['f1_loss_streak'] = all_data_doubled.groupby(by=['fighter_1'])['f1_loss_streak'].shift(periods=1,fill_value=0)\n",
    "all_data_doubled = all_data_doubled.drop(columns=['results_2','cumsum','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the f1 features to duplicate as f2\n",
    "\n",
    "features_to_duplicate = ['f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "       'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "       'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "       'f1_ufc_total_fights', 'f1_win_streak','f1_loss_streak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define f1_to_f2 duplicating feature - parameters\n",
    "\n",
    "def dup_f1f2(features_to_duplicate, all_data_doubled):\n",
    "\n",
    "    # Create a list of total features to merge on - include fighter_1 and date\n",
    "    total_features = features_to_duplicate + ['fighter_1','date']\n",
    "    \n",
    "    # Duplicate all_data_doubled with a subset of the features to duplicate\n",
    "    dup_df = all_data_doubled[total_features].copy()\n",
    "    \n",
    "    # Find and replace f1 as f2 in the column names\n",
    "    dup_df.columns = [i.replace(\"f1\",\"f2\") for i in dup_df.columns]\n",
    "    \n",
    "    # Merge the duplicated dataset (R) unto the first dataset (L), left_on = fighter_1, right_on = fighter_1\n",
    "    all_data_doubled = all_data_doubled.merge(dup_df, on=['fighter_1','date'])\n",
    "    \n",
    "    return all_data_doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_doubled = dup_f1f2(features_to_duplicate, all_data_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_mean(df,gb_feat,replace):\n",
    "    # Groupby weight class, then find the mean f1_reach\n",
    "    gb = df.groupby(by=gb_feat)[replace].mean()\n",
    "\n",
    "    # Subset all_data_doubled for the rows where f1_reach is NA\n",
    "    subset = df[df[replace].isna()]\n",
    "\n",
    "    # Merge the mean values\n",
    "    df.loc[df[replace].isna(),[replace]] = subset[gb_feat].map(gb)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace reach NAs reaches with appropriate means\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f1_reach')\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f2_reach')\n",
    "\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f1_height')\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f2_height')\n",
    "\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f1_weight')\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f2_weight')\n",
    "\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'f1_total_fights','f1_dob')\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'f2_total_fights','f2_dob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f1_weight')\n",
    "all_data_doubled = fill_na_mean(all_data_doubled,'weight_class','f2_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the f1 features on which to create f1 - f2 features\n",
    "diff_feat = ['fighter_1','fighter_2',\n",
    "        'f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "       'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "       'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "       'f1_ufc_total_fights', 'f1_cum_rnd', 'f1_cum_ftime', 'f1_cum_strikes',\n",
    "       'f1_cum_td', 'f1_cum_sub', 'f2_cum_rnd', 'f2_cum_ftime',\n",
    "       'f2_cum_strikes', 'f2_cum_td', 'f2_cum_sub', 'f1_stpm', 'f1_tdpm',\n",
    "       'f1_subpm', 'f2_stpm', 'f2_tdpm', 'f2_subpm', 'f1_win_streak',\n",
    "       'f1_loss_streak', 'f2_ufc_draw', 'f2_ufc_loss', 'f2_ufc_nc',\n",
    "       'f2_ufc_win', 'f2_height', 'f2_weight', 'f2_reach', 'f2_stance',\n",
    "       'f2_dob', 'f2_total_fights', 'f2_all_win', 'f2_all_loss', 'f2_all_draw',\n",
    "       'f2_ufc_total_fights', 'f2_win_streak', 'f2_loss_streak'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
