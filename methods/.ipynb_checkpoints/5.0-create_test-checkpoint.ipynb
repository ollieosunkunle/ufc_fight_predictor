{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_path = 'C:/Users/ollieosunkunle/Google Drive/Work, career and education/Programming_data_science/UFC fight predictor/Version 2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = abs_path + \"test_data/covington_vs_woodley.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the difference dictionary (note - this is copied from the create_training_df model)\n",
    "diff_dict = {\n",
    "    'f1_ufc_draw':'f2_ufc_draw',\n",
    "    'f1_ufc_loss':'f2_ufc_loss',\n",
    "    'f1_ufc_nc':'f2_ufc_nc',\n",
    "    'f1_ufc_win':'f2_ufc_win',\n",
    "    'f1_height':'f2_height',\n",
    "    'f1_weight':'f2_weight',\n",
    "    'f1_reach':'f2_reach',\n",
    "    'f1_stance':'f2_stance',\n",
    "    'f1_dob':'f2_dob',\n",
    "    'f1_all_win':'f2_all_win',\n",
    "    'f1_all_loss':'f2_all_loss',\n",
    "    'f1_all_draw':'f2_all_draw',\n",
    "    'f1_total_fights':'f2_total_fights',\n",
    "    'f1_ufc_total_fights':'f2_ufc_total_fights',\n",
    "    'f1_cum_rnd':'f2_cum_rnd',\n",
    "    'f1_cum_ftime':'f2_cum_ftime',\n",
    "    'f1_cum_strikes':'f2_cum_strikes',\n",
    "    'f1_cum_td':'f2_cum_td',\n",
    "    'f1_cum_sub':'f2_cum_sub',\n",
    "    'f1_stpm':'f2_stpm',\n",
    "    'f1_tdpm':'f2_tdpm',\n",
    "    'f1_subpm':'f2_subpm',\n",
    "    'f1_win_streak':'f2_win_streak',\n",
    "    'f1_loss_streak':'f2_loss_streak'\n",
    "}\n",
    "\n",
    "# Define the features to keep\n",
    "to_keep_2 = ['date','results','fighter_1','fighter_2', \n",
    " 'f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "   'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "   'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "   'f1_ufc_total_fights', 'f1_cum_rnd', 'f1_cum_ftime', 'f1_cum_strikes',\n",
    "   'f1_cum_td', 'f1_cum_sub', 'f2_cum_rnd', 'f2_cum_ftime',\n",
    "   'f2_cum_strikes', 'f2_cum_td', 'f2_cum_sub', 'f1_stpm', 'f1_tdpm',\n",
    "   'f1_subpm', 'f2_stpm', 'f2_tdpm', 'f2_subpm', 'f1_win_streak',\n",
    "   'f1_loss_streak', 'f2_ufc_draw', 'f2_ufc_loss', 'f2_ufc_nc',\n",
    "   'f2_ufc_win', 'f2_height', 'f2_weight', 'f2_reach', 'f2_stance',\n",
    "   'f2_dob', 'f2_total_fights', 'f2_all_win', 'f2_all_loss', 'f2_all_draw',\n",
    "   'f2_ufc_total_fights', 'f2_win_streak', 'f2_loss_streak', 'd_ufc_draw',\n",
    "   'd_ufc_loss', 'd_ufc_nc', 'd_ufc_win', 'd_height', 'd_weight',\n",
    "   'd_reach', 'd_stance', 'd_dob', 'd_all_win', 'd_all_loss', 'd_all_draw',\n",
    "   'd_ufc_total_fights', 'd_cum_rnd', 'd_cum_ftime', 'd_cum_strikes',\n",
    "   'd_cum_td', 'd_cum_sub', 'd_stpm', 'd_tdpm', 'd_subpm', 'd_win_streak',\n",
    "   'd_loss_streak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ollieosunkunle\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#Import various useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con = \"sqlite:///../database/ufc_data.db\"\n",
    "con = create_engine(sql_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_file,encoding='latin-1',usecols = ['fighter_1','fighter_2'])\n",
    "\n",
    "#test_df = pd.read_csv(test_file, encoding='latin-1', sep='\\t',usecols = ['fighter_1','fighter_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_sql(\"SELECT * FROM train_df_v3\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which fighter names from test_set are missing and identify the closest matches\n",
    "display('Original fighter list',test_df)\n",
    "\n",
    "train_fighters = train_df['fighter_1'].unique() #Create a list of unique train_fighters\n",
    "test_fighters = test_df['fighter_1'].append(test_df['fighter_2']) #Create a list of unique test_fighters\n",
    "missing_fighters = test_fighters[~test_fighters.isin(train_fighters)].reset_index(drop=True) #Find the missing fighters in the test_dataset\n",
    "closest_matches = missing_fighters.apply(lambda x: process.extract(x,train_fighters,limit=1)[0])\n",
    "fighter_lu = pd.concat([missing_fighters,closest_matches],axis=1)\n",
    "fighter_lu.columns = ['original_name','new_name']\n",
    "threshold = 85 #Set the matching threshold to replace an old fighter's name with a new one\n",
    "fighter_lu['new_name'] = fighter_lu['new_name'].apply(lambda x: x[0] if x[1] > threshold else np.nan) #Set to nan names that don't meet threshold\n",
    "\n",
    "#display('Missing fighters and lookups',fighter_lu)\n",
    "\n",
    "# Replace the names in the original test dataset\n",
    "replacement_dict = fighter_lu.set_index('original_name').to_dict()['new_name']\n",
    "for f in ['fighter_1','fighter_2']:\n",
    "    test_df[f] = test_df[f].replace(replacement_dict, value=None)\n",
    "\n",
    "#display('Merged and replaced missing fighters',test_df)\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "display('Final fighter list',test_df)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the train_df for f1_features - dictionary keys\n",
    "\n",
    "# Note - there is an issue. Need to create an aligned dataset of all the latest fighter results across both fighter_1 and fighter_2 to append. Consider using melt to achieve\n",
    "\n",
    "feature_sub_f1 = list(diff_dict.keys()) #List of f1_keys on which to subset\n",
    "feature_sub_f2 = list(diff_dict.values()) #List of f1_keys on which to subset\n",
    "train_df_subset_f1 = train_df[['date','fighter_1']+feature_sub_f1].sort_values(by=['date'],ascending=False).drop_duplicates(subset=['fighter_1'],keep='first')\n",
    "train_df_subset_f2 = train_df[['date','fighter_2']+feature_sub_f2].sort_values(by=['date'],ascending=False).drop_duplicates(subset=['fighter_2'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a long lift of all latest fighter results\n",
    "\n",
    "#Replace 1 and 2 in column names, so that both subsets have same names\n",
    "for f in [[train_df_subset_f1,\"1\"], [train_df_subset_f2,\"2\"]]:\n",
    "    f[0].columns = [i.replace(f[1],\"0\") for i in f[0].columns]\n",
    "    \n",
    "#Append subset 1 and subset 2\n",
    "train_df_subset = train_df_subset_f1.append(train_df_subset_f2, ignore_index = True).sort_values(by=['date'],ascending=False).drop_duplicates(subset=['fighter_0'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features to the test data frame\n",
    "\n",
    "for i in [['fighter_1','1'],['fighter_2','2']]:\n",
    "    test_df = test_df.merge(train_df_subset,left_on=i[0],right_on='fighter_0',how='left').drop(columns=['date','fighter_0'])\n",
    "    test_df.columns = [c.replace(\"0\",i[1]) for c in test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference features\n",
    "\n",
    "# Calculate difference features\n",
    "for col_1, col_2 in diff_dict.items():\n",
    "    test_df[col_1.replace(\"f1\",\"d\")] = test_df[col_1] - test_df[col_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del to_keep_2[0:2] #Removes first two elements in the list -> assumes that these are date and results\n",
    "test_df_sub = test_df[to_keep_2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_sub.to_sql('test_df',con,if_exists='replace',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
