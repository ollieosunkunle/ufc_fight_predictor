{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import various useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con = \"sqlite:///../database/ufc_data.db\"\n",
    "con = create_engine(sql_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_df = pd.read_sql(\"SELECT * FROM clean_fighter_data\", con)\n",
    "bout_df = pd.read_sql(\"SELECT * FROM clean_bout_data\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_df(con,fighter_df,bout_df):\n",
    "    #Add losses to the data for fighter_1\n",
    "    all_data = bout_df.copy()\n",
    "    all_data_losses = all_data[all_data.results=='win'].copy() #Make a copy of all_data with just the wins\n",
    "\n",
    "    all_data_losses['results'] = all_data_losses.results.str.replace(\"win\",\"loss\") #Replace win with loss\n",
    "    all_data_losses = all_data_losses.rename(columns={'fighter_1':'temp'}).rename(columns={'fighter_2':'fighter_1'}).rename(columns={'temp':'fighter_2'}) #Rename the columns\n",
    "    all_data_doubled = pd.concat([all_data,all_data_losses]).sort_values(by='date') #Aggregate data and sort the values\n",
    "    \n",
    "    #Count the number of ufc wins\n",
    "    all_data_doubled['ufc_f1_wins_and_losses'] = all_data_doubled.groupby(by=['fighter_1','results']).event_name.cumcount() + 1 #Long forms wins and losses\n",
    "    all_data_mini = all_data_doubled[['date','fighter_1','fighter_2','results','ufc_f1_wins_and_losses']].copy() #Subset the data in preparation for pivotting\n",
    "\n",
    "    all_data_pivot = all_data_mini.pivot_table(index=['date','fighter_1','fighter_2'], columns='results').reset_index() #Pivot to create wide columns of wins\n",
    "    all_data_pivot.columns = ['date','fighter_1','fighter_2','draw','loss','nc','win'] #Rename the columns to remove multi-indexing\n",
    "\n",
    "    #filled_nas = all_data_pivot.groupby(by='fighter_1')['draw','loss','nc','win'].fillna(method='bfill') #Fillnas - first fill with previous values\n",
    "    filled_nas = all_data_pivot.groupby(by='fighter_1')['draw','loss','nc','win'].fillna(method='ffill') #Fillnas - then fill with forward values\n",
    "\n",
    "    for i in ['draw','loss','nc','win']: #Replace the columns in all_data pivot with that from filled_nas\n",
    "        all_data_pivot[i] = filled_nas[i]\n",
    "        all_data_pivot[i] = all_data_pivot.groupby(by='fighter_1')[i].shift()\n",
    "\n",
    "    all_data_pivot = all_data_pivot.fillna(0) #Fill the remaining NAs wtith zeros\n",
    "    all_data_doubled = all_data_doubled.merge(all_data_pivot, on=['date','fighter_1','fighter_2']) #Left merge all_data_doubled - creates draw, loss, nc and win columns\n",
    "    all_data_doubled = all_data_doubled.drop(columns=['ufc_f1_wins_and_losses']) #Drop the unneeded column\n",
    "\n",
    "    for i in ['draw','loss','nc','win']:\n",
    "        all_data_doubled = all_data_doubled.rename(columns={i:'ufc_'+i}) \n",
    "        \n",
    "    #Merge in the fighter df\n",
    "    fighter_df = fighter_df.rename(columns={'wins':'max_wins','losses':'max_losses','draws':'max_draws'})\n",
    "\n",
    "    fighter_columns = ['height', 'weight', 'reach', 'stance', 'dob',\n",
    "           'strikes_landed_per_min', 'strike_accuracy', 'strikes_absorbed_per_min',\n",
    "           'strike_defense', 'takedowns_per_15_min', 'takedown_accuracy',\n",
    "           'takedown_defense', 'submission_attempts_per_15_min', 'max_wins',\n",
    "           'max_losses', 'max_draws', 'total_fights', 'win_pct', 'loss_pct',\n",
    "           'draw_pct']\n",
    "\n",
    "    all_data_doubled = all_data_doubled.merge(fighter_df,left_on='fighter_1',right_on='fighter_name')\n",
    "\n",
    "    for i in fighter_columns:\n",
    "        all_data_doubled = all_data_doubled.rename(columns={i:'f1_'+i}) \n",
    "\n",
    "    all_data_doubled = all_data_doubled.drop(columns='fighter_name')\n",
    "    \n",
    "    #Create total fights features\n",
    "    max_fights = all_data_doubled[['fighter_1','ufc_win','ufc_draw','ufc_loss','ufc_nc']].groupby(by='fighter_1').max()\n",
    "    max_fights.columns = ['f1_max_ufc_win', 'f1_max_ufc_draw', 'f1_max_ufc_loss', 'f1_max_ufc_nc']\n",
    "    all_data_doubled = all_data_doubled.merge(max_fights,on='fighter_1',how='left')\n",
    "\n",
    "    all_data_doubled = all_data_doubled.rename(columns={'ufc_win':'f1_ufc_win','ufc_draw':'f1_ufc_draw','ufc_loss':'f1_ufc_loss','ufc_nc':'f1_ufc_nc'}) #Renaming of columns to make fighter explicit\n",
    "\n",
    "    ufc_cols = ['f1_ufc_win','f1_ufc_loss','f1_ufc_draw']\n",
    "    max_ufc_cols = ['f1_max_ufc_win', 'f1_max_ufc_loss', 'f1_max_ufc_draw']\n",
    "    max_all_cols = ['f1_max_wins', 'f1_max_losses', 'f1_max_draws']\n",
    "    all_cols = ['f1_all_win','f1_all_loss','f1_all_draw']\n",
    "\n",
    "    for i in range(len(ufc_cols)):\n",
    "        all_data_doubled[all_cols[i]] = all_data_doubled[max_all_cols[i]] - all_data_doubled[max_ufc_cols[i]] + all_data_doubled[ufc_cols[i]]\n",
    "\n",
    "    all_data_doubled = all_data_doubled.drop(columns=['f1_max_wins','f1_max_losses','f1_max_draws','f1_max_ufc_win','f1_max_ufc_draw','f1_max_ufc_loss','f1_max_ufc_nc'])\n",
    "    all_data_doubled['f1_total_fights'] = all_data_doubled['f1_all_win'] + all_data_doubled['f1_all_loss'] + all_data_doubled['f1_all_draw'] + all_data_doubled['f1_ufc_nc']\n",
    "    \n",
    "    #Drop the leakage columns\n",
    "    leakage_cols = ['f1_strikes_landed_per_min','f1_strike_accuracy','f1_strikes_absorbed_per_min','f1_strike_defense','f1_takedowns_per_15_min','f1_takedown_accuracy','f1_takedown_defense','f1_submission_attempts_per_15_min','f1_win_pct','f1_loss_pct','f1_draw_pct']\n",
    "    all_data_doubled = all_data_doubled.drop(columns = leakage_cols)\n",
    "    \n",
    "    #Create total UFC fights feature\n",
    "    all_data_doubled['f1_ufc_total_fights'] = all_data_doubled['f1_ufc_draw'] + all_data_doubled['f1_ufc_loss'] + all_data_doubled['f1_ufc_nc'] + all_data_doubled['f1_ufc_win']\n",
    "\n",
    "    #Sum cumulative features\n",
    "    orig_f1_features = ['no_rounds','total_fight_time','fighter_1_strikes','fighter_1_td','fighter_1_sub']\n",
    "    cum_f1_target = ['f1_cum_rnd','f1_cum_ftime','f1_cum_strikes','f1_cum_td','f1_cum_sub']\n",
    "\n",
    "    for i in range(len(orig_f1_features)):\n",
    "        all_data_doubled[cum_f1_target[i]] = all_data_doubled.groupby(by=['fighter_1'])[orig_f1_features[i]].cumsum()\n",
    "\n",
    "    orig_f2_features = ['no_rounds','total_fight_time','fighter_2_strikes','fighter_2_td','fighter_2_sub']\n",
    "    cum_f2_target = ['f2_cum_rnd','f2_cum_ftime','f2_cum_strikes','f2_cum_td','f2_cum_sub']\n",
    "\n",
    "    for i in range(len(orig_f2_features)):\n",
    "        all_data_doubled[cum_f2_target[i]] = all_data_doubled.groupby(by=['fighter_2'])[orig_f2_features[i]].cumsum()\n",
    "\n",
    "    f1_per_min_orig = ['f1_cum_strikes','f1_cum_td','f1_cum_sub']\n",
    "    f1_per_min_target = ['f1_stpm','f1_tdpm','f1_subpm']\n",
    "\n",
    "    for i in range(len(f1_per_min_orig)):\n",
    "        all_data_doubled[f1_per_min_target[i]] = all_data_doubled[f1_per_min_orig[i]] / all_data_doubled['f1_cum_ftime']\n",
    "\n",
    "    f2_per_min_orig = ['f2_cum_strikes','f2_cum_td','f2_cum_sub']\n",
    "    f2_per_min_target = ['f2_stpm','f2_tdpm','f2_subpm']\n",
    "\n",
    "    for i in range(len(f2_per_min_orig)):\n",
    "        all_data_doubled[f2_per_min_target[i]] = all_data_doubled[f2_per_min_orig[i]] / all_data_doubled['f2_cum_ftime']\n",
    "        \n",
    "    #Create a win streak feature for f1\n",
    "    all_data_doubled['results_2'] = np.where(all_data_doubled.results=='win',0,1)\n",
    "    all_data_doubled['cumsum'] = all_data_doubled.groupby(by=['fighter_1']).results_2.cumsum()\n",
    "    all_data_doubled['val'] = np.where(all_data_doubled.results=='win',1,0)\n",
    "    all_data_doubled['f1_win_streak'] = all_data_doubled.groupby(by=['fighter_1','cumsum']).val.cumsum()\n",
    "    all_data_doubled['f1_win_streak'] = all_data_doubled.groupby(by=['fighter_1'])['f1_win_streak'].shift(periods=1,fill_value=0)\n",
    "    all_data_doubled = all_data_doubled.drop(columns=['results_2','cumsum','val'])\n",
    "    \n",
    "    #Create a loss streak feature for f1\n",
    "    all_data_doubled['results_2'] = np.where(all_data_doubled.results=='loss',0,1)\n",
    "    all_data_doubled['cumsum'] = all_data_doubled.groupby(by=['fighter_1']).results_2.cumsum()\n",
    "    all_data_doubled['val'] = np.where(all_data_doubled.results=='loss',1,0)\n",
    "    all_data_doubled['f1_loss_streak'] = all_data_doubled.groupby(by=['fighter_1','cumsum']).val.cumsum()\n",
    "    all_data_doubled['f1_loss_streak'] = all_data_doubled.groupby(by=['fighter_1'])['f1_loss_streak'].shift(periods=1,fill_value=0)\n",
    "    all_data_doubled = all_data_doubled.drop(columns=['results_2','cumsum','val'])\n",
    "    \n",
    "    #List the f1 features to duplicate as f2\n",
    "    features_to_duplicate = ['f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "           'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "           'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "           'f1_ufc_total_fights', 'f1_win_streak','f1_loss_streak']\n",
    "    \n",
    "    all_data_doubled = dup_f1f2(features_to_duplicate, all_data_doubled)\n",
    "    \n",
    "    #Define groupby columns and na columns to be replaced\n",
    "    replace_na = [\n",
    "        ['weight_class','f1_reach'],\n",
    "        ['weight_class','f2_reach'],\n",
    "        ['weight_class','f1_height'],\n",
    "        ['weight_class','f2_height'],\n",
    "        ['weight_class','f1_weight'],\n",
    "        ['weight_class','f2_weight'],\n",
    "        ['f1_total_fights','f1_dob'],\n",
    "        ['f2_total_fights','f2_dob'],\n",
    "        ['weight_class','f1_weight'],\n",
    "        ['weight_class','f2_weight'],\n",
    "        ['weight_class','f1_cum_strikes'],\n",
    "        ['weight_class','f1_cum_td'],\n",
    "        ['weight_class','f1_cum_sub'],\n",
    "        ['weight_class','f2_cum_rnd'],\n",
    "        ['weight_class','f2_cum_ftime'],\n",
    "        ['weight_class','f2_cum_strikes'],\n",
    "        ['weight_class','f2_cum_td'],\n",
    "        ['weight_class','f2_cum_sub'],\n",
    "        ['weight_class','f1_stpm'],\n",
    "        ['weight_class','f1_tdpm'],\n",
    "        ['weight_class','f1_subpm'],\n",
    "        ['weight_class','f2_stpm'],\n",
    "        ['weight_class','f2_tdpm'],\n",
    "        ['weight_class','f2_subpm']\n",
    "    ]\n",
    "\n",
    "    #Loop through and replace\n",
    "    for item in replace_na:\n",
    "        all_data_doubled = fill_na_mean(all_data_doubled,item[0],item[1])\n",
    "        \n",
    "    #List the f1 features on which to create f1 - f2 features\n",
    "    diff_feat = ['f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "           'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "           'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "           'f1_ufc_total_fights', 'f1_cum_rnd', 'f1_cum_ftime', 'f1_cum_strikes',\n",
    "           'f1_cum_td', 'f1_cum_sub', 'f2_cum_rnd', 'f2_cum_ftime',\n",
    "           'f2_cum_strikes', 'f2_cum_td', 'f2_cum_sub', 'f1_stpm', 'f1_tdpm',\n",
    "           'f1_subpm', 'f2_stpm', 'f2_tdpm', 'f2_subpm', 'f1_win_streak',\n",
    "           'f1_loss_streak', 'f2_ufc_draw', 'f2_ufc_loss', 'f2_ufc_nc',\n",
    "           'f2_ufc_win', 'f2_height', 'f2_weight', 'f2_reach', 'f2_stance',\n",
    "           'f2_dob', 'f2_total_fights', 'f2_all_win', 'f2_all_loss', 'f2_all_draw',\n",
    "           'f2_ufc_total_fights', 'f2_win_streak', 'f2_loss_streak'\n",
    "    ]\n",
    "    \n",
    "    #Difference dictionary\n",
    "    diff_dict = {\n",
    "        'f1_ufc_draw':'f2_ufc_draw',\n",
    "        'f1_ufc_loss':'f2_ufc_loss',\n",
    "        'f1_ufc_nc':'f2_ufc_nc',\n",
    "        'f1_ufc_win':'f2_ufc_win',\n",
    "        'f1_height':'f2_height',\n",
    "        'f1_weight':'f2_weight',\n",
    "        'f1_reach':'f2_reach',\n",
    "        'f1_stance':'f2_stance',\n",
    "        'f1_dob':'f2_dob',\n",
    "        'f1_all_win':'f2_all_win',\n",
    "        'f1_all_loss':'f2_all_loss',\n",
    "        'f1_all_draw':'f2_all_draw',\n",
    "        'f1_ufc_total_fights':'f2_ufc_total_fights',\n",
    "        'f1_cum_rnd':'f2_cum_rnd',\n",
    "        'f1_cum_ftime':'f2_cum_ftime',\n",
    "        'f1_cum_strikes':'f2_cum_strikes',\n",
    "        'f1_cum_td':'f2_cum_td',\n",
    "        'f1_cum_sub':'f2_cum_sub',\n",
    "        'f1_stpm':'f2_stpm',\n",
    "        'f1_tdpm':'f2_tdpm',\n",
    "        'f1_subpm':'f2_subpm',\n",
    "        'f1_win_streak':'f2_win_streak',\n",
    "        'f1_loss_streak':'f2_loss_streak'\n",
    "    }\n",
    "    \n",
    "    print_inf(all_data_doubled)\n",
    "    \n",
    "    train_df = all_data_doubled.copy()\n",
    "    \n",
    "    # Calculate difference features\n",
    "    for col_1, col_2 in diff_dict.items():\n",
    "        train_df[col_1.replace(\"f1\",\"d\")] = train_df[col_1] - train_df[col_2]\n",
    "        \n",
    "    # Define the features to keep\n",
    "    to_keep = ['date', 'results', 'fighter_1', 'fighter_2',\n",
    "         'f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "           'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "           'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "           'f1_ufc_total_fights', 'f1_cum_rnd', 'f1_cum_ftime', 'f1_cum_strikes',\n",
    "           'f1_cum_td', 'f1_cum_sub', 'f2_cum_rnd', 'f2_cum_ftime',\n",
    "           'f2_cum_strikes', 'f2_cum_td', 'f2_cum_sub', 'f1_stpm', 'f1_tdpm',\n",
    "           'f1_subpm', 'f2_stpm', 'f2_tdpm', 'f2_subpm', 'f1_win_streak',\n",
    "           'f1_loss_streak', 'f2_ufc_draw', 'f2_ufc_loss', 'f2_ufc_nc',\n",
    "           'f2_ufc_win', 'f2_height', 'f2_weight', 'f2_reach', 'f2_stance',\n",
    "           'f2_dob', 'f2_total_fights', 'f2_all_win', 'f2_all_loss', 'f2_all_draw',\n",
    "           'f2_ufc_total_fights', 'f2_win_streak', 'f2_loss_streak', 'd_ufc_draw',\n",
    "           'd_ufc_loss', 'd_ufc_nc', 'd_ufc_win', 'd_height', 'd_weight',\n",
    "           'd_reach', 'd_stance', 'd_dob', 'd_all_win', 'd_all_loss', 'd_all_draw',\n",
    "           'd_ufc_total_fights', 'd_cum_rnd', 'd_cum_ftime', 'd_cum_strikes',\n",
    "           'd_cum_td', 'd_cum_sub', 'd_stpm', 'd_tdpm', 'd_subpm', 'd_win_streak',\n",
    "           'd_loss_streak']\n",
    "\n",
    "    train_df_sub = train_df[to_keep]\n",
    "    \n",
    "    # Segment for only wins and losses\n",
    "    results_to_keep = ['win','loss']\n",
    "    train_df_sub = train_df_sub[train_df_sub['results'].isin(results_to_keep)]\n",
    "    \n",
    "    var_print = ['results','fighter_1','fighter_2','f1_win_streak','f2_win_streak','d_win_streak']\n",
    "    train_df_sub.loc[train_df_sub.fighter_1 == \"Tecia Torres\",var_print]\n",
    "    \n",
    "    to_keep_2 = ['fighter_1','fighter_2','date','results', \n",
    "     'f1_ufc_draw', 'f1_ufc_loss', 'f1_ufc_nc',\n",
    "       'f1_ufc_win', 'f1_height', 'f1_weight', 'f1_reach', 'f1_stance',\n",
    "       'f1_dob', 'f1_total_fights', 'f1_all_win', 'f1_all_loss', 'f1_all_draw',\n",
    "       'f1_ufc_total_fights', 'f1_cum_rnd', 'f1_cum_ftime', 'f1_cum_strikes',\n",
    "       'f1_cum_td', 'f1_cum_sub', 'f2_cum_rnd', 'f2_cum_ftime',\n",
    "       'f2_cum_strikes', 'f2_cum_td', 'f2_cum_sub', 'f1_stpm', 'f1_tdpm',\n",
    "       'f1_subpm', 'f2_stpm', 'f2_tdpm', 'f2_subpm', 'f1_win_streak',\n",
    "       'f1_loss_streak', 'f2_ufc_draw', 'f2_ufc_loss', 'f2_ufc_nc',\n",
    "       'f2_ufc_win', 'f2_height', 'f2_weight', 'f2_reach', 'f2_stance',\n",
    "       'f2_dob', 'f2_total_fights', 'f2_all_win', 'f2_all_loss', 'f2_all_draw',\n",
    "       'f2_ufc_total_fights', 'f2_win_streak', 'f2_loss_streak', 'd_ufc_draw',\n",
    "       'd_ufc_loss', 'd_ufc_nc', 'd_ufc_win', 'd_height', 'd_weight',\n",
    "       'd_reach', 'd_stance', 'd_dob', 'd_all_win', 'd_all_loss', 'd_all_draw',\n",
    "       'd_ufc_total_fights', 'd_cum_rnd', 'd_cum_ftime', 'd_cum_strikes',\n",
    "       'd_cum_td', 'd_cum_sub', 'd_stpm', 'd_tdpm', 'd_subpm', 'd_win_streak',\n",
    "       'd_loss_streak']\n",
    "\n",
    "    train_df_sub_2 = train_df_sub[to_keep_2]\n",
    "    \n",
    "    train_df_sub_2.to_sql('train_df_v3',con,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define f1_to_f2 duplicating feature - parameters\n",
    "def dup_f1f2(features_to_duplicate, all_data_doubled):\n",
    "\n",
    "    # Create a list of total features to merge on - include fighter_1 and date\n",
    "    total_features = features_to_duplicate + ['fighter_1','date']\n",
    "    \n",
    "    # Duplicate all_data_doubled with a subset of the features to duplicate\n",
    "    dup_df = all_data_doubled[total_features].copy()\n",
    "    \n",
    "    # Find and replace f1 as f2 in the column names\n",
    "    dup_df.columns = [i.replace(\"f1\",\"f2\") for i in dup_df.columns]\n",
    "    dup_df = dup_df.rename(columns={'fighter_1':'fighter_2'})\n",
    "    \n",
    "    # Merge the duplicated dataset (R) unto the first dataset (L), left_on = fighter_1, right_on = fighter_1\n",
    "    all_data_doubled = all_data_doubled.merge(dup_df, on=['fighter_2','date'])\n",
    "    \n",
    "    return all_data_doubled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_mean(df,gb_feat,replace):\n",
    "    # Groupby weight class, then find the mean f1_reach\n",
    "    gb = df.groupby(by=gb_feat)[replace].mean()\n",
    "\n",
    "    # Subset all_data_doubled for the rows where f1_reach is NA\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    subset = df[df[replace].isna()].copy()\n",
    "\n",
    "    # Merge the mean values\n",
    "    df.loc[df[replace].isna(),[replace]] = subset[gb_feat].map(gb)\n",
    "    \n",
    "    del gb, subset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for infinite values\n",
    "def print_inf(df):\n",
    "    for i in df.columns:\n",
    "        if (np.sum(df[i] == np.inf)>0): print(i, np.sum(df[i] == np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ollieosunkunle\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "create_train_df(con,fighter_df,bout_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Create a long form of data for EDA\\nplot_df = all_data_doubled.copy()\\n#plot_df['results'] = plot_df['results'].map({'win':1,'loss':0,'draw':-1,'nc':-2})\\nplot_melt = plot_df.melt(id_vars='results',value_vars=diff_feat)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Create a long form of data for EDA\n",
    "plot_df = all_data_doubled.copy()\n",
    "#plot_df['results'] = plot_df['results'].map({'win':1,'loss':0,'draw':-1,'nc':-2})\n",
    "plot_melt = plot_df.melt(id_vars='results',value_vars=diff_feat)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Display the summary statistics to see if there are meaningful differences\\nsummary = plot_melt[plot_melt.results.isin(['win','loss'])].pivot_table(values='value',index='variable',columns='results',aggfunc='mean')\\nsummary['difference'] = summary.win - summary.loss\\nsummary['pct_difference'] = ((summary.win/summary.loss) - 1)*100\\nsummary = summary[['win','loss','difference','pct_difference']]\\n#summary.to_csv('summary.csv',index=True)\\nsummary\\ntrain_df_sub.to_csv('train_df_sub.csv',index=False)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Display the summary statistics to see if there are meaningful differences\n",
    "summary = plot_melt[plot_melt.results.isin(['win','loss'])].pivot_table(values='value',index='variable',columns='results',aggfunc='mean')\n",
    "summary['difference'] = summary.win - summary.loss\n",
    "summary['pct_difference'] = ((summary.win/summary.loss) - 1)*100\n",
    "summary = summary[['win','loss','difference','pct_difference']]\n",
    "#summary.to_csv('summary.csv',index=True)\n",
    "summary\n",
    "train_df_sub.to_csv('train_df_sub.csv',index=False)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
